{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from tqdm.notebook import tqdm\n","import pandas as pd \n","from time import sleep\n","\n","import torch\n","import torch.nn as nn \n","import torch.nn.functional as F \n","import torch.optim as optim \n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import  transforms\n",""]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# activate GPU\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",""]},{"cell_type":"markdown","metadata":{},"source":["# load dataset in mini-batch format by DataLoader"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["class MNIST(Dataset):\n","    def __init__(self, src_path, transform=None):\n","        self.transform = transform\n","        df = pd.read_csv(src_path)\n","        y_np = df.iloc[:, 0].values\n","        X_np = df.iloc[:, 1:].values/255.0\n","\n","        self.y = torch.from_numpy(y_np)\n","        X = torch.from_numpy(X_np)\n","        self.X = torch.reshape(X,(-1, 1, 28 ,28)).float()\n","    \n","    def __len__(self):\n","        assert len(self.y) == self.X.shape[0]\n","        return len(self.y)\n","\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","        X_sub = self.X[idx, :]\n","        y_sub = self.y[idx]\n","\n","        if self.transform:\n","            X_sub = self.transform(X_sub)\n","\n","        return X_sub, y_sub\n","\n",""]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["\n","transformer = transforms.Compose([\n","    transforms.Normalize(mean=(0.5,), std=(0.5,))\n","])\n","\n","dataset = MNIST('../../data/datasets/train.csv')\n","batch_size = 20\n","loader = DataLoader(dataset,batch_size=batch_size, shuffle=True, num_workers=0)\n","\n",""]},{"cell_type":"markdown","metadata":{},"source":["# build ConvNet architecture"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["class ConvNet(nn.Module):\n","\n","    def __init__(self):\n","        super(ConvNet, self).__init__()\n","        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3)\n","        self.conv2 = nn.Conv2d(in_channels=6, out_channels=32, kernel_size=3)\n","        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.flatten = nn.Linear(in_features=32*5*5, out_features=128)\n","        self.fc1 = nn.Linear(in_features=128, out_features=64)\n","        self.fc2 = nn.Linear(in_features=64, out_features=10)\n","    \n","    def forward(self, x):\n","        in_size = x.size(0)\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = x.view(-1, 32*5*5)\n","        x = F.relu(self.flatten(x))\n","        x = F.relu(self.fc1(x))\n","        #x = F.relu(self.fc2(x))     ## this is the output layer.\n","        #x = F.log_softmax(x)        ## this is the logits layer.\n","        x = self.fc2(x)\n","        return x \n","\n","model = ConvNet()\n","model = model.to(device)\n",""]},{"cell_type":"markdown","metadata":{},"source":["# define loss function, matrics and optimization algorithm."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["\n","criterion = nn.CrossEntropyLoss()\n","#criterion = nn.NLLLoss()\n","\n","optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",""]},{"cell_type":"markdown","metadata":{},"source":[" train the model"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["[1 : 1] loss : 2.285472869873047\n","[1 : 101] loss : 2.307098865509033\n","[1 : 201] loss : 2.30499529838562\n","[1 : 301] loss : 2.2906596660614014\n","[1 : 401] loss : 2.281426191329956\n","[1 : 501] loss : 2.310518264770508\n","[1 : 601] loss : 2.283036470413208\n","[1 : 701] loss : 2.301621437072754\n","[1 : 801] loss : 2.328727960586548\n","[1 : 901] loss : 2.2873597145080566\n","[1 : 1001] loss : 2.2834925651550293\n","[1 : 1101] loss : 2.3116073608398438\n","[1 : 1201] loss : 2.310828685760498\n","[1 : 1301] loss : 2.3072009086608887\n","[1 : 1401] loss : 2.3113882541656494\n","[1 : 1501] loss : 2.322164297103882\n","[1 : 1601] loss : 2.2963826656341553\n","[1 : 1701] loss : 2.306656837463379\n","[1 : 1801] loss : 2.283966302871704\n","[1 : 1901] loss : 2.2896173000335693\n","[1 : 2001] loss : 2.3055148124694824\n","Finished Training\n"]}],"source":["\n","epochs = 1\n","for epoch in range(epochs):\n","        for i, data in enumerate(loader):\n","            inputs, labels = data \n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            optimizer.zero_grad()\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            if i % 100 == 0:\n","                print(f'[{epoch+1} : {i+1}] loss : {loss.item()}')\n","print('Finished Training')\n",""]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2100 [00:00<?, ?batch/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e1f39b9e1a74404a7a88d5a550e12b8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Finished Training\n"]}],"source":["\n","epochs = 1\n","for epoch in range(epochs):\n","    with tqdm(loader, unit='batch', position=0, leave=True) as progress_bar:\n","        for data in progress_bar:\n","            progress_bar.set_description(f'Epoch {epoch}:')\n","\n","            inputs, labels = data \n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            optimizer.zero_grad()\n","\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            correct = (torch.argmax(outputs, axis=1) == labels).sum().item()\n","            accuracy = correct / batch_size\n","            progress_bar.set_postfix(loss=loss.item(), accuracy=100. * accuracy)\n","            #progress_bar.update()\n","\n","print('Finished Training')\n",""]},{"cell_type":"markdown","metadata":{},"source":["# save model results"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["\n","torch.save(model.state_dict(), '../../data/models/convNet_torch.pt')"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["torch.save(loader, '../../data/models/dataloader.pth')"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":2}}